endpoint,field_path,required,type,sync_status,sync_http_status,sync_error_code,sync_evidence,sync_notes,stream_status,stream_http_status,stream_error_code,stream_evidence,stream_notes,deprecated,replacement
/chat/completions,audio,N,Optional[ChatCompletionAudioParam],,,,,,,,,,,N,
/chat/completions,frequency_penalty,N,Optional[float],,,,,,,,,,,N,
/chat/completions,function_call,N,FunctionCall,,,,,,,,,,,Y,tool_choice
/chat/completions,functions,N,Iterable[Function],,,,,,,,,,,Y,tools
/chat/completions,logit_bias,N,"Optional[Dict[str, int]]",,,,,,,,,,,N,
/chat/completions,logprobs,N,Optional[bool],,,,,,,,,,,N,
/chat/completions,max_completion_tokens,N,Optional[int],,,,,,,,,,,N,
/chat/completions,max_tokens,N,Optional[int],,,,,,,,,,,Y,max_completion_tokens
/chat/completions,messages,Y,Required[Iterable[ChatCompletionMessageParam]],,,,,,,,,,,N,
/chat/completions,metadata,N,Optional[Metadata],,,,,,,,,,,N,
/chat/completions,modalities,N,"Optional[List[Literal['text', 'audio']]]",,,,,,,,,,,N,
/chat/completions,model,Y,"Required[Union[str, ChatModel]]",,,,,,,,,,,N,
/chat/completions,n,N,Optional[int],,,,,,,,,,,N,
/chat/completions,parallel_tool_calls,N,bool,,,,,,,,,,,N,
/chat/completions,prediction,N,Optional[ChatCompletionPredictionContentParam],,,,,,,,,,,N,
/chat/completions,presence_penalty,N,Optional[float],,,,,,,,,,,N,
/chat/completions,prompt_cache_key,N,str,,,,,,,,,,,N,
/chat/completions,prompt_cache_retention,N,"Optional[Literal['in-memory', '24h']]",,,,,,,,,,,N,
/chat/completions,reasoning_effort,N,Optional[ReasoningEffort],,,,,,,,,,,N,
/chat/completions,response_format,N,ResponseFormat,,,,,,,,,,,N,
/chat/completions,safety_identifier,N,str,,,,,,,,,,,N,
/chat/completions,seed,N,Optional[int],,,,,,,,,,,Y,(beta/不保证确定性，观察 system_fingerprint)
/chat/completions,service_tier,N,"Optional[Literal['auto', 'default', 'flex', 'scale', 'priority']]",,,,,,,,,,,N,
/chat/completions,stop,N,"Union[Optional[str], SequenceNotStr[str], None]",,,,,,,,,,,N,
/chat/completions,store,N,Optional[bool],,,,,,,,,,,N,
/chat/completions,stream,N,Optional[Literal[False]] | Literal[True] | Omit,,,,,,,,,,,N,
/chat/completions,stream_options,N,Optional[ChatCompletionStreamOptionsParam],,,,,,,,,,,N,
/chat/completions,temperature,N,Optional[float],,,,,,,,,,,N,
/chat/completions,tool_choice,N,ChatCompletionToolChoiceOptionParam,,,,,,,,,,,N,
/chat/completions,tools,N,Iterable[ChatCompletionToolUnionParam],,,,,,,,,,,N,
/chat/completions,top_logprobs,N,Optional[int],,,,,,,,,,,N,
/chat/completions,top_p,N,Optional[float],,,,,,,,,,,N,
/chat/completions,user,N,str,,,,,,,,,,,Y,safety_identifier 或 prompt_cache_key
/chat/completions,verbosity,N,"Optional[Literal['low', 'medium', 'high']]",,,,,,,,,,,N,
/chat/completions,web_search_options,N,WebSearchOptions,,,,,,,,,,,N,
/responses,background,N,Optional[bool],,,,,,,,,,,N,
/responses,context_management,N,Optional[Iterable[ContextManagement]],,,,,,,,,,,N,
/responses,conversation,N,Optional[Conversation],,,,,,,,,,,N,
/responses,include,N,Optional[List[ResponseIncludable]],,,,,,,,,,,N,
/responses,input,N,"Union[str, ResponseInputParam]",,,,,,,,,,,N,
/responses,instructions,N,Optional[str],,,,,,,,,,,N,
/responses,max_output_tokens,N,Optional[int],,,,,,,,,,,N,
/responses,max_tool_calls,N,Optional[int],,,,,,,,,,,N,
/responses,metadata,N,Optional[Metadata],,,,,,,,,,,N,
/responses,model,N,ResponsesModel,,,,,,,,,,,N,
/responses,parallel_tool_calls,N,Optional[bool],,,,,,,,,,,N,
/responses,previous_response_id,N,Optional[str],,,,,,,,,,,N,
/responses,prompt,N,Optional[ResponsePromptParam],,,,,,,,,,,N,
/responses,prompt_cache_key,N,str,,,,,,,,,,,N,
/responses,prompt_cache_retention,N,"Optional[Literal['in-memory', '24h']]",,,,,,,,,,,N,
/responses,reasoning,N,Optional[Reasoning],,,,,,,,,,,N,
/responses,safety_identifier,N,str,,,,,,,,,,,N,
/responses,service_tier,N,"Optional[Literal['auto', 'default', 'flex', 'scale', 'priority']]",,,,,,,,,,,N,
/responses,store,N,Optional[bool],,,,,,,,,,,N,
/responses,stream,N,Optional[Literal[False]] | Literal[True] | Omit,,,,,,,,,,,N,
/responses,stream_options,N,Optional[StreamOptions],,,,,,,,,,,N,
/responses,temperature,N,Optional[float],,,,,,,,,,,N,
/responses,text,N,ResponseTextConfigParam,,,,,,,,,,,N,
/responses,tool_choice,N,ToolChoice,,,,,,,,,,,N,
/responses,tools,N,Iterable[ToolParam],,,,,,,,,,,N,
/responses,top_logprobs,N,Optional[int],,,,,,,,,,,N,
/responses,top_p,N,Optional[float],,,,,,,,,,,N,
/responses,truncation,N,"Optional[Literal['auto', 'disabled']]",,,,,,,,,,,N,
/responses,user,N,str,,,,,,,,,,,Y,

